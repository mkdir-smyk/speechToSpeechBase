{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b84947ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import collections\n",
    "import queue\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "import sounddevice as sd\n",
    "from faster_whisper import WhisperModel\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19554ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained(self.model_name)\n",
    "        self.model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    def analyze(self, text):\n",
    "        if not text.strip():\n",
    "            return {\"sentiment\": \"neutral\", \"confidence\": 0.5, \"score\": -1}\n",
    "            \n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        sentiment = torch.argmax(probs, dim=1).item()  # 0 = negative, 1 = positive\n",
    "        confidence = probs[0][sentiment].item()\n",
    "        \n",
    "        return {\n",
    "            \"sentiment\": \"positive\" if sentiment == 1 else \"negative\",\n",
    "            \"confidence\": confidence,\n",
    "            \"score\": sentiment\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4ab74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_utterance(sample_rate=16000, frame_duration=30):\n",
    "    vad = webrtcvad.Vad(3) \n",
    "    frame_size = int(sample_rate * frame_duration / 1000)\n",
    "    audio_q = queue.Queue()\n",
    "    \n",
    "    def audio_callback(indata, frames, time_info, status):\n",
    "        audio_q.put(bytes(indata))\n",
    "    \n",
    "    with sd.RawInputStream(samplerate=sample_rate, blocksize=frame_size,\n",
    "                         dtype='int16', channels=1, callback=audio_callback):\n",
    "        ring_buffer = collections.deque(maxlen=5)  \n",
    "        voiced_frames = []\n",
    "        speech_detected = False\n",
    "        silence_duration = 0\n",
    "        required_silence = 1.0 \n",
    "        \n",
    "        while True:\n",
    "            frame = audio_q.get()\n",
    "            is_speech = vad.is_speech(frame, sample_rate)\n",
    "            \n",
    "            if is_speech:\n",
    "                if not speech_detected:\n",
    "                    print(\"...\", flush=True)\n",
    "                    speech_detected = True\n",
    "                    voiced_frames.extend(ring_buffer) \n",
    "                voiced_frames.append(frame)\n",
    "                silence_duration = 0\n",
    "            else:\n",
    "                if speech_detected:\n",
    "                    silence_duration += frame_duration / 4000.0\n",
    "                    voiced_frames.append(frame) \n",
    "                    \n",
    "                    if silence_duration >= required_silence:\n",
    "                        return b''.join(voiced_frames)\n",
    "                else:\n",
    "                    ring_buffer.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c9bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(model, audio_bytes):\n",
    "    audio_np = np.frombuffer(audio_bytes, dtype=np.int16)\n",
    "    waveform = torch.from_numpy(audio_np.astype(np.float32) / 32768.0).unsqueeze(0)\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    torchaudio.save(buffer, waveform, 16000, format='wav')\n",
    "    buffer.seek(0)\n",
    "\n",
    "    segments, _ = model.transcribe(buffer)\n",
    "    text = \" \".join([seg.text for seg in segments]).strip()\n",
    "    print(f\"You: {text}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e34f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tts():\n",
    "    tts_model = torch.hub.load('snakers4/silero-models', 'silero_tts', \n",
    "                             language='en', speaker='v3_en')[0]\n",
    "    return tts_model\n",
    "\n",
    "def speak(text, tts_model, speaker='en_99', sample_rate=24000):\n",
    "    try:\n",
    "        audio = tts_model.apply_tts(text=text, \n",
    "                                  speaker=speaker, \n",
    "                                  sample_rate=sample_rate)\n",
    "        sd.play(audio, sample_rate)\n",
    "        sd.wait()\n",
    "    except Exception as e:\n",
    "        print(f\"TTS Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c9cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        self.context = []\n",
    "        self.last_user_message = \"\"\n",
    "        self.sentiment_analyzer = SentimentAnalyzer()\n",
    "        self.conversation_topics = {\n",
    "            \"default\": {\n",
    "                \"positive\": [\n",
    "                    \"That's wonderful! What's making you so happy today?\",\n",
    "                    \"You sound really pleased about that!\",\n",
    "                    \"Great to hear you're in good spirits!\"\n",
    "                ],\n",
    "                \"negative\": [\n",
    "                    \"I'm sorry to hear that. Would you like to talk about it?\",\n",
    "                    \"That sounds difficult. How are you handling it?\",\n",
    "                    \"I can tell this is bothering you. What would help?\"\n",
    "                ],\n",
    "                \"neutral\": [\n",
    "                    \"What would you like to talk about?\",\n",
    "                    \"What's on your mind?\",\n",
    "                    \"Tell me more about that.\"\n",
    "                ]\n",
    "            },\n",
    "            \"tech\": {\n",
    "                \"positive\": [\n",
    "                    \"Glad you're excited about tech! What specifically interests you?\",\n",
    "                    \"Tech can be so rewarding when it works well!\",\n",
    "                    \"What tech has caught your attention lately?\"\n",
    "                ],\n",
    "                \"negative\": [\n",
    "                    \"Tech frustrations are so common these days. What's the issue?\",\n",
    "                    \"Having computer problems again?\",\n",
    "                    \"What's not working the way it should?\"\n",
    "                ],\n",
    "                \"neutral\": [\n",
    "                    \"What tech topics interest you these days?\",\n",
    "                    \"How's your tech life going?\",\n",
    "                    \"Working on anything interesting with technology?\"\n",
    "                ]\n",
    "            },\n",
    "            \"personal\": {\n",
    "                \"positive\": [\n",
    "                    \"You sound really happy about that!\",\n",
    "                    \"It's great to hear good news!\",\n",
    "                    \"What's bringing you joy these days?\"\n",
    "                ],\n",
    "                \"negative\": [\n",
    "                    \"I'm here to listen if you want to talk.\",\n",
    "                    \"That sounds challenging. How are you coping?\",\n",
    "                    \"Would it help to talk about what's bothering you?\"\n",
    "                ],\n",
    "                \"neutral\": [\n",
    "                    \"How are things going for you?\",\n",
    "                    \"What's new in your life?\",\n",
    "                    \"How have you been lately?\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        self.occasional_quips = [\n",
    "            \"That's what I would say if I had more feelings.\",\n",
    "            \"Fascinating - tell me more.\",\n",
    "            \"Interesting perspective!\",\n",
    "            \"You always have such unique thoughts.\",\n",
    "            \"That's a new one for my conversation database.\"\n",
    "        ]\n",
    "    \n",
    "    def analyze_sentiment(self, text):\n",
    "        return self.sentiment_analyzer.analyze(text)\n",
    "    \n",
    "    def update_context(self, user_input):\n",
    "        sentiment = self.analyze_sentiment(user_input)\n",
    "        self.last_user_message = user_input\n",
    "        self.context.append((\"user\", user_input, sentiment))\n",
    "        if len(self.context) > 5:\n",
    "            self.context.pop(0)\n",
    "    \n",
    "    def should_add_quip(self):\n",
    "        # Only 10% chance to add a quip, and only if the conversation is light\n",
    "        if (self.context and \n",
    "            self.context[-1][2][\"sentiment\"] == \"positive\" and \n",
    "            len(self.context) > 2 and \n",
    "            np.random.random() < 0.1):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def generate_follow_up(self):\n",
    "        if not self.context:\n",
    "            return np.random.choice(self.conversation_topics[\"default\"][\"neutral\"])\n",
    "        \n",
    "        last_interaction = self.context[-1]\n",
    "        sentiment = last_interaction[2][\"sentiment\"]\n",
    "        \n",
    "        topic = \"default\"\n",
    "        if any(word in self.last_user_message.lower() for word in [\"computer\", \"tech\", \"code\", \"programming\"]):\n",
    "            topic = \"tech\"\n",
    "        elif any(word in self.last_user_message.lower() for word in [\"i\", \"me\", \"my\", \"feel\", \"feeling\"]):\n",
    "            topic = \"personal\"\n",
    "        \n",
    "        response = np.random.choice(self.conversation_topics[topic][sentiment])\n",
    "        \n",
    "        if self.should_add_quip():\n",
    "            quip = np.random.choice(self.occasional_quips)\n",
    "            response = f\"{response} {quip}\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def format_prompt(self, user_input):\n",
    "        self.update_context(user_input)\n",
    "        sentiment = self.context[-1][2]\n",
    "        \n",
    "        history = \"\\n\".join([f\"{who}: {msg}\" for who, msg, _ in self.context[-2:]])\n",
    "        \n",
    "        return f\"\"\"Continue this conversation naturally as a friendly, helpful AI assistant. \n",
    "        User sentiment: {sentiment['sentiment']} (confidence: {sentiment['confidence']:.2f}).\n",
    "        \n",
    "        Guidelines:\n",
    "        1. Be warm and personable but not overly familiar\n",
    "        2. Use natural spoken language that sounds good when read aloud\n",
    "        3. Only use humor when it feels completely natural (about 10% of responses)\n",
    "        4. Keep responses concise (1-2 sentences)\n",
    "        5. Match the user's emotional tone:\n",
    "           - Positive: supportive and engaged\n",
    "           - Negative: empathetic and helpful\n",
    "           - Neutral: curious and interested\n",
    "        \n",
    "        Example good responses:\n",
    "        - \"That's great progress! What's next?\"\n",
    "        - \"I understand why that would be frustrating.\"\n",
    "        - \"What aspects of that interest you most?\"\n",
    "        \n",
    "        Avoid:\n",
    "        - Forced humor or jokes\n",
    "        - Overly casual language when inappropriate\n",
    "        - Any physical action descriptions\n",
    "        \n",
    "        Conversation history:\n",
    "        {history}\n",
    "        \n",
    "        Respond to: {user_input}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d8b4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, tts_model, conversation):\n",
    "    try:\n",
    "        formatted_prompt = conversation.format_prompt(prompt)\n",
    "        \n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            data=json.dumps({\n",
    "                \"model\": \"mistral\",\n",
    "                \"prompt\": formatted_prompt,\n",
    "                \"stream\": True,\n",
    "                \"options\": {\n",
    "                    \"temperature\": 0.85,\n",
    "                    \"max_tokens\": 120,\n",
    "                }\n",
    "            }),\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        \n",
    "        full_response = \"\"\n",
    "        buffer = \"\"\n",
    "        sentence_end_chars = {'.', '?', '!', ',', ';', ':'}\n",
    "        \n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                chunk = json.loads(line.decode('utf-8'))\n",
    "                token = chunk.get(\"response\", \"\")\n",
    "                \n",
    "                full_response += token\n",
    "                buffer += token\n",
    "\n",
    "                if token in sentence_end_chars or token.isspace():\n",
    "                    if buffer.strip():\n",
    "                        speak(buffer, tts_model, speaker='en_99')\n",
    "                        buffer = \"\"\n",
    "        \n",
    "        if buffer.strip():\n",
    "            speak(buffer, tts_model, speaker='en_99')\n",
    "        \n",
    "        print(f\"AI: {full_response.strip()}\")\n",
    "        conversation.context.append((\"assistant\", full_response.strip(), {\"sentiment\": \"neutral\"}))\n",
    "        \n",
    "        return full_response.strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        error_msg = \"Hmm, I got a bit confused there. What were we saying?\"\n",
    "        speak(error_msg, tts_model)\n",
    "        return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d9f2fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Soumyak/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "You: I have a ceiling no couldo, so you can help me.\n"
     ]
    }
   ],
   "source": [
    "tts_model = init_tts()\n",
    "stt_model = WhisperModel(\"tiny.en\", device=\"cuda\", compute_type=\"int8_float32\")\n",
    "conversation = ConversationManager()\n",
    "\n",
    "speak(\"Hello, what do you have in mind today...?\", tts_model)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        audio = record_utterance()\n",
    "        if not audio:\n",
    "            continue\n",
    "            \n",
    "        user_text = transcribe_audio(stt_model, audio)\n",
    "        if not user_text:\n",
    "            continue\n",
    "            \n",
    "        bot_response = generate_response(user_text, tts_model, conversation)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    speak(\"Goodbye!\", tts_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
