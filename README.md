#LocalVoiceMind

##Introduction

In an era where digital privacy and environmental stewardship are paramount, LocalVoiceMind offers a sophisticated, locally executed conversational AI, safeguarding your confidences whilst treading lightly upon our planet’s resources.

##Description

A fully local conversational AI that listens to your voice, understands your emotions, and responds with empathy—all running on your own machine. Built as a Jupyter Notebook, this project combines speech recognition, sentiment analysis, and text-to-speech to create a privacy-focused, engaging voice assistant.

##Prerequisites

Python 3.12.6 or later
A microphone for voice input
CUDA-enabled GPU for faster processing with faster-whisper and torch
A local mistral model server running at http://localhost:11434/api/generate (e.g., via Ollama)

Refer to requirements fle to get a complete overview of the required libraries

##License
This project is licensed under the MIT License. See the LICENSE file for details.

##Acknowledgments
Built with love using faster-whisper, transformer, and silero_tts.
Inspired by the idea of a caring, local AI companion.
